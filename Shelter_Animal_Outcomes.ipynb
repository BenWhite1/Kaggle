{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unknown dog breeds:\n",
      "\n",
      "['Picardy Sheepdog', 'Dogo Argentino', 'English Pointer', 'Plott Hound', 'Unknown', 'Bedlington Terr', 'Glen Of Imaal', 'Yorkshire', 'Bichon Frise', 'Entlebucher', 'Dutch Shepherd', 'Landseer', 'Wire Hair Fox Terrier', 'Spanish Mastiff', 'Carolina Dog', 'Port Water Dog', 'Jindo', 'American Eskimo', 'Sealyham Terr', 'Treeing Tennesse Brindle', 'Feist', 'American Pit Bull Terrier', 'English Coonhound', 'Patterdale Terr', 'Swiss Hound', 'Treeing Cur', 'Presa Canario', 'Pbgv', 'Bull Terrier Miniature', 'Anatol Shepherd', 'English Shepherd', 'Chinese Crested', 'German Pointer', 'Hovawart', 'Bruss Griffon', 'Alaskan Husky', 'Redbone Hound', 'Germaned Pointer', 'Lowchen', 'West Highland', 'Old English Bulldog', 'Schnauzer Giant', 'Mexican Hairless', 'Bluetick Hound', 'Podengo Pequeno', 'Chesa Bay Retr', 'Softed Wheaten Terrier', 'Hound', 'Cavalier Span', 'Boykin Span']\n",
      "\n",
      "\n",
      "Dropping NaNs reduced the dataframe by 36 rows.\n",
      "\n",
      "x_train:\n",
      "[[ 0.01907681 -0.84753698  0.9709089  -1.14381355  0.26070944 -1.01593459\n",
      "  -1.53744487]\n",
      " [-1.13355108  1.17988952 -0.18296478  1.70664104  1.17321829 -1.01593459\n",
      "   0.44291894]\n",
      " [ 0.30723378 -0.84753698 -0.99067636 -1.29249598 -0.26813092 -1.01593459\n",
      "   0.44291894]\n",
      " [-0.55723714  1.17988952  1.43245837  1.77036208  1.29765132  0.73799111\n",
      "  -1.53744487]\n",
      " [-1.42170805  1.17988952  0.9709089  -0.11153268  0.51994491  0.73799111\n",
      "   0.44291894]]\n",
      "PCA - variance retained: 1.0%\n",
      "Best parameters: {'estimator__kernel': 'rbf', 'estimator__C': 1, 'estimator__degree': 1, 'estimator__gamma': 0.0001}\n",
      "Best score: 0.2\n",
      "[ 0.3         0.37777778  0.45555556  0.53333333  0.61111111  0.68888889\n",
      "  0.76666667  0.84444444  0.92222222  1.        ]\n",
      "<type 'numpy.ndarray'>\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-1240bc794cba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[1;31m# Plot learning curve for best params\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m \u001b[0mtitle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Learning curve (SVM)'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m \u001b[0mplot_learning_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf_tuned\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mylim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.05\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#cv)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-1240bc794cba>\u001b[0m in \u001b[0;36mplot_learning_curve\u001b[1;34m(estimator, title, X, y, ylim, cv, n_jobs, train_sizes)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Score\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m     train_sizes, train_scores, test_scores = learning_curve(estimator, X, y, cv=cv, \n\u001b[1;32m--> 153\u001b[1;33m                                                             n_jobs=n_jobs, train_sizes=train_sizes)\n\u001b[0m\u001b[0;32m    154\u001b[0m     \u001b[0mtrain_scores_mean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_scores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m     \u001b[0mtrain_scores_std\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_scores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\bw8\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\sklearn\\learning_curve.pyc\u001b[0m in \u001b[0;36mlearning_curve\u001b[1;34m(estimator, X, y, train_sizes, cv, scoring, exploit_incremental_learning, n_jobs, pre_dispatch, verbose)\u001b[0m\n\u001b[0;32m    120\u001b[0m     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[1;31m# Make a list since we will be iterating multiple times over the folds\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 122\u001b[1;33m     \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcheck_cv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    123\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\bw8\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.pyc\u001b[0m in \u001b[0;36mcheck_cv\u001b[1;34m(cv, X, y, classifier)\u001b[0m\n\u001b[0;32m   1675\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1676\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'binary'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'multiclass'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1677\u001b[1;33m                 \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1678\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1679\u001b[0m                 \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\bw8\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, y, n_folds, shuffle, random_state)\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtest_fold_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mper_label_splits\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mper_label_cvs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_split\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munique_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mper_label_splits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 533\u001b[1;33m                 \u001b[0mlabel_test_folds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_folds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    534\u001b[0m                 \u001b[1;31m# the test split can be too big because we used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    535\u001b[0m                 \u001b[1;31m# KFold(max(c, self.n_folds), self.n_folds) instead of\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEZCAYAAACNebLAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/x8DvMDQBrvckwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xec7f320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "from sklearn import cross_validation, metrics, preprocessing\n",
    "from sklearn import svm\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.learning_curve import learning_curve, validation_curve #temporary\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "def encode_ordinal(data_col):\n",
    "    \"\"\"\n",
    "    Function encodes categorical data ordinally, accepting a dataframe column\n",
    "    and returning the encoded dataframe column with a mapping list.\n",
    "    \"\"\"\n",
    "    \n",
    "    mapping = []\n",
    "    \n",
    "    categories = list(set(data_col.values))\n",
    "    random.shuffle(categories)\n",
    "    for idx, val in enumerate(categories):\n",
    "        data_col.loc[data_col == val] = str(idx)\n",
    "    data_col = data_col.astype(int)\n",
    "    mapping.append({'mapping': [(x[1], x[0]) for x in list(enumerate(categories))]},)\n",
    "\n",
    "    return data_col, mapping\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "def breed_to_breed_group(data_col):   \n",
    "    \"\"\"\n",
    "    Function simplifies dog breeds into dog breed categories, yielding more\n",
    "    examples per category. Accepts a dataframe column of dog breeds and returns\n",
    "    a dataframe column of dog breeds mapped to categories. Function uses\n",
    "    data and structure of Andy's Kaggle script, which can be found at: \n",
    "    kaggle.com/andraszsom/shelter-animal-outcomes/dog-breeds-dog-groups/comments\n",
    "    \"\"\"\n",
    "    \n",
    "    # Import Andy's breed groups as dictionary\n",
    "    fname = './Input/dog_breed_to_category.csv'\n",
    "    breed_to_category_dict = pd.read_csv(fname, names=['Category'], index_col=0, header=None).to_dict()\n",
    "    \n",
    "    unknowns = []\n",
    "    for idx, element in enumerate(data_col):\n",
    "        # Simplify breed by removing unnecessary words\n",
    "        element = element.replace(' Shorthair','')\n",
    "        element = element.replace(' Medium Hair','')\n",
    "        element = element.replace(' Longhair','')\n",
    "        element = element.replace(' Wirehair','')\n",
    "        element = element.replace(' Rough','')\n",
    "        element = element.replace(' Smooth Coat','')\n",
    "        element = element.replace(' Smooth','')\n",
    "        element = element.replace(' Black/Tan','')\n",
    "        element = element.replace('Black/Tan ','')\n",
    "        element = element.replace(' Flat Coat','')\n",
    "        element = element.replace('Flat Coat ','')\n",
    "        element = element.replace(' Coat','')\n",
    "\n",
    "        # If more than one breed, split using '/' separator\n",
    "        if '/' in element:\n",
    "            i = 0\n",
    "            split_element = element.split('/')\n",
    "            a = ''\n",
    "            for j in split_element:\n",
    "                if j[-3:] == 'Mix':\n",
    "                    if not j[:-4] in breed_to_category_dict['Category'].keys():\n",
    "                        a += 'Unknown Mix'\n",
    "                        unknowns.append(j[:-4])\n",
    "                    else:\n",
    "                        a += breed_to_category_dict['Category'][j[:-4]]\n",
    "                else:\n",
    "                    if not j in breed_to_category_dict['Category'].keys():\n",
    "                        a += 'Unknown'\n",
    "                        unknowns.append(j)\n",
    "                    else:\n",
    "                        a += breed_to_category_dict['Category'][j]\n",
    "                a += ' / '\n",
    "            a = a[:-3]\n",
    "            data_col.loc[idx] = a\n",
    "        else:\n",
    "            if element[-3:] == 'Mix':\n",
    "                data_col.loc[idx] = element[:-4]\n",
    "                if not data_col.loc[idx] in breed_to_category_dict['Category'].keys():\n",
    "                    data_col.loc[idx] = \"Unknown Mix\"\n",
    "                    unknowns.append(element[:-4])\n",
    "            else:\n",
    "                data_col.loc[idx] = element\n",
    "                if not data_col.loc[idx] in breed_to_category_dict['Category'].keys():\n",
    "                    data_col.loc[idx] = \"Unknown\"\n",
    "                    unknowns.append(element)\n",
    "    \n",
    "    print('Unknown dog breeds: %s\\n' % list(set(unknowns)))\n",
    "    \n",
    "    breeds = set([val for val in breed_to_category_dict['Category'].keys()])\n",
    "    # Map breed to category\n",
    "    for breed in breeds:\n",
    "        data_col.loc[data_col == breed] = breed_to_category_dict['Category'][breed]        \n",
    "    return data_col\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "def find_number(string):\n",
    "    number = re.match('^[0-9]+', string).group(0)\n",
    "    return int(number)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "def age_to_months(data_col):\n",
    "    '''\n",
    "    Takes list of strings with ages in the regex format ^[0-9]+\\b\\s+\n",
    "    and returns a list of integers with the age in months. E.g. \n",
    "    '2 years' becomes '24'.\n",
    "    '''\n",
    "    \n",
    "    data_col = data_col.reset_index(drop=True)\n",
    "    ages = set(data_col)\n",
    "    for age in ages:\n",
    "        if age[-3:] == 'day' or age[-4:] == 'days':\n",
    "            age_number = round(find_number(age) * 12/365)\n",
    "        elif age[-4:] == 'week' or age[-5:] == 'weeks':\n",
    "            age_number = round(find_number(age) * 12/52)\n",
    "        elif age[-5:] == 'month' or age[-6:] == 'months':\n",
    "            age_number = find_number(age)\n",
    "        elif age[-4:] == 'year' or age[-5:] == 'years':\n",
    "            age_number = find_number(age) * 12\n",
    "        else:\n",
    "            age_number = -1\n",
    "            print age_number\n",
    "        data_col.loc[data_col == age] = int(age_number)\n",
    "\n",
    "    return data_col\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=1, train_sizes=np.linspace(.3, 1.0, 10)):\n",
    "    \"\"\"\n",
    "    Generate a simple plot of the test and traning learning curve. Taken from:\n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html.\n",
    "    Currently fails.\n",
    "    \"\"\"\n",
    "    print train_sizes\n",
    "    print type(train_sizes)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "                estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "def plot_validation_curve(estimator, X, y, param_range=np.logspace(-9, 3, 9), cv=None):\n",
    "\n",
    "    train_scores, test_scores = validation_curve(\n",
    "        estimator, X, y, param_name=\"estimator__gamma\", param_range=param_range,\n",
    "        cv=cv, scoring=\"accuracy\", n_jobs=1)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "    plt.title(\"Validation Curve with SVM\")\n",
    "    plt.xlabel(\"$\\gamma$\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    #plt.ylim(0.0, 1.1)\n",
    "    plt.semilogx(param_range, train_scores_mean, label=\"Training score\", color=\"r\")\n",
    "    plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.2, color=\"r\")\n",
    "    plt.semilogx(param_range, test_scores_mean, label=\"Cross-validation score\",\n",
    "                 color=\"g\")\n",
    "    plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.2, color=\"g\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "## Helpfully taken from Eugenia Uchaeva's 'Take a look at the data' script:\n",
    "## https://www.kaggle.com/uchayder/shelter-animal-outcomes/take-a-look-at-the-data\n",
    "\n",
    "def get_sex(element):\n",
    "    \"\"\"\n",
    "    Takes string input, searches for sex within string, returns sex\n",
    "    \"\"\"\n",
    "    element = str(element)\n",
    "    if element.find('Male') >= 0: return 'male'\n",
    "    if element.find('Female') >= 0: return 'female'\n",
    "    return 'unknown'\n",
    "\n",
    "def get_neutered(element):\n",
    "    \"\"\"\n",
    "    Takes string input, searches for neutered status within string, returns \n",
    "    status\n",
    "    \"\"\"\n",
    "    element = str(element)\n",
    "    if element.find('Spayed') >= 0: return 'neutered'\n",
    "    if element.find('Neutered') >= 0: return 'neutered'\n",
    "    if element.find('Intact') >= 0: return 'intact'\n",
    "    return 'unknown'\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "data_raw = pd.read_csv('./input/train.csv')\n",
    "\n",
    "original_rows = data_raw.shape[0]\n",
    "data_encoded = data_raw\n",
    "#print data_encoded.head()\n",
    "\n",
    "# Split SexuopnOutcome into Sex and NeuteredStatus\n",
    "data_encoded['Sex'] = data_encoded.SexuponOutcome.apply(get_sex)\n",
    "data_encoded['NeuteredStatus'] = data_encoded.SexuponOutcome.apply(get_neutered)\n",
    "\n",
    "# Convert ages into months, being careful to remove NaNs\n",
    "data_encoded = data_encoded.dropna(subset = ['AgeuponOutcome'])\n",
    "data_encoded.AgeuponOutcome = age_to_months(data_encoded.AgeuponOutcome)\n",
    "data_encoded = data_encoded.dropna(subset = ['AgeuponOutcome'])\n",
    "\n",
    "# Categorise breeds into breed groups\n",
    "data_encoded.Breed[data_encoded.AnimalType == 'Dog'] = breed_to_breed_group(data_encoded.Breed[data_encoded.AnimalType == 'Dog'])\n",
    "\n",
    "new_rows = data_encoded.shape[0]\n",
    "print('Dropping NaNs reduced the dataframe by %i rows.\\n' % (original_rows - new_rows))\n",
    "\n",
    "# Start with ordinal encoding, then try binary encoding and compare\n",
    "# performance. Ordinal encoding may be acceptable for age.\n",
    "data_encoded.DateTime = pd.to_datetime(data_encoded.DateTime).dt.month\n",
    "data_encoded.AnimalType, animaltype_mapping = encode_ordinal(data_encoded.AnimalType)\n",
    "data_encoded.Sex, sex_mapping = encode_ordinal(data_encoded.Sex)\n",
    "data_encoded.NeuteredStatus, neuteredstatus_mapping = encode_ordinal(data_encoded.NeuteredStatus)\n",
    "data_encoded.AgeuponOutcome, ageuponoutcome_mapping = encode_ordinal(data_encoded.AgeuponOutcome)\n",
    "data_encoded.Breed, breed_mapping = encode_ordinal(data_encoded.Breed)\n",
    "data_encoded.Color, color_mapping = encode_ordinal(data_encoded.Color)\n",
    "\n",
    "# Line below would perform one-hot encoding\n",
    "#df = pd.concat([data_raw, pd.get_dummies(data_raw['Breed']).rename(columns = lambda x: 'Breed_' + str(x))], axis=1)\n",
    "\n",
    "data_encoded = data_encoded.drop(['Name', 'AnimalID', 'SexuponOutcome'], axis = 1) #Naughtily discarding name for now\n",
    "data_labels = data_encoded[['OutcomeType', 'OutcomeSubtype']]\n",
    "data_encoded = data_encoded.drop(data_labels, axis = 1)\n",
    "#print data_encoded.head()\n",
    "\n",
    "## Split dataset and train a classifier\n",
    "x_train, x_test, y_train, y_test = cross_validation.train_test_split(\n",
    "    data_encoded, data_labels[[0]], test_size = 0.3, random_state = 1)\n",
    "\n",
    "# Fit scaler on x_train\n",
    "xy_scaler = preprocessing.StandardScaler()\n",
    "xy_scaler.fit(x_train)\n",
    "x_train = xy_scaler.transform(x_train)\n",
    "print('x_train:\\n%s' % x_train[0:5,:])\n",
    "\n",
    "# Install PCA to reduce dimensions\n",
    "pca = PCA(0.95) # Return 95% of the variance\n",
    "x_train = pca.fit(x_train).transform(x_train)\n",
    "print('PCA - variance retained: %s%%' % sum(pca.explained_variance_ratio_))\n",
    "\n",
    "# Define SVM - basic, not optimised. Use cross validation / grid search \n",
    "# to find optimal hyperparameters\n",
    "cv = cross_validation.ShuffleSplit(data_encoded.shape[1], n_iter=50,\n",
    "                                       test_size=0.2, random_state=0)\n",
    "clf_untuned = OneVsRestClassifier(svm.SVC(kernel='rbf', random_state=0))\n",
    "params = {\n",
    "    'estimator__C': [1, 10, 100],\n",
    "    'estimator__gamma': [0.00001, 0.0001, 0.001],\n",
    "    'estimator__kernel': ['poly', 'rbf'],\n",
    "    'estimator__degree':[1, 2, 3],\n",
    "}\n",
    "clf_tuned = GridSearchCV(clf_untuned, cv=cv, param_grid=params)\n",
    "clf_tuned.fit(x_train, y_train)\n",
    "print('Best parameters: %s' % clf_tuned.best_params_)\n",
    "print('Best score: %s' % clf_tuned.best_score_)\n",
    "\n",
    "# Plot learning curve for best params\n",
    "#title = 'Learning curve (SVM)'\n",
    "#plot_learning_curve(clf_tuned.best_estimator_, title, x_train, y_train, ylim=(0.6, 1.05), cv=cv)\n",
    "#plt.show()\n",
    "\n",
    "# Plot validation curve\n",
    "plot_validation_curve(clf_tuned.best_estimator_, x_train, y_train, cv=cv)\n",
    "plt.show()\n",
    "\n",
    "# Fit scaler, PCA to x_test\n",
    "x_test = xy_scaler.transform(x_test)\n",
    "x_test = pca.transform(x_test)\n",
    "\n",
    "predicted = clf_tuned.predict(x_test)\n",
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (clf_untuned, metrics.classification_report(y_test, predicted)))\n",
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.610889110889\n"
     ]
    }
   ],
   "source": [
    "accuracy = clf_tuned.score(x_test, y_test)\n",
    "print accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
