{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping NaNs reduced the dataframe by 24 rows.\n",
      "\n",
      "Unknown dog breeds: ['Picardy Sheepdog', 'Dogo Argentino', 'English Pointer', 'Plott Hound', 'Unknown', 'Bedlington Terr', 'Glen Of Imaal', 'Yorkshire', 'Bichon Frise', 'Entlebucher', 'Dutch Shepherd', 'Cirneco', 'Landseer', 'Wire Hair Fox Terrier', 'Coton De Tulear', 'Spanish Mastiff', 'Carolina Dog', 'Port Water Dog', 'Jindo', 'American Eskimo', 'Sealyham Terr', 'Treeing Tennesse Brindle', 'Feist', 'American Pit Bull Terrier', 'English Coonhound', 'Patterdale Terr', 'Swiss Hound', 'Treeing Cur', 'Presa Canario', 'Pbgv', 'Bull Terrier Miniature', 'Dachshund Stan', 'Anatol Shepherd', 'English Shepherd', 'Eng Toy Spaniel', 'Chinese Crested', 'German Pointer', 'Hovawart', 'Bruss Griffon', 'Alaskan Husky', 'Redbone Hound', 'Germaned Pointer', 'Lowchen', 'West Highland', 'Dandie Dinmont', 'Old English Bulldog', 'Schnauzer Giant', 'Mexican Hairless', 'Bluetick Hound', 'Podengo Pequeno', 'Chesa Bay Retr', 'Softed Wheaten Terrier', 'Hound', 'Cavalier Span', 'Boykin Span']\n",
      "\n",
      "      AgeuponOutcome  AnimalID  AnimalType  Breed  Color  DateTime     ID  \\\n",
      "Name                                                                        \n",
      "1              38161     38161       38161  38161  38161     38161  11450   \n",
      "\n",
      "      OutcomeSubtype  OutcomeType  Regime  SexuponOutcome    Sex  \\\n",
      "Name                                                               \n",
      "1              24549        38161   38161           38160  38161   \n",
      "\n",
      "      NeuteredStatus   Year  Month    Day  \n",
      "Name                                       \n",
      "1              38161  38161  38161  38161  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bw8\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:276: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\bw8\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\pandas\\core\\indexing.py:117: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "C:\\Users\\bw8\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:328: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\bw8\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:334: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\bw8\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:338: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       AgeuponOutcome  AnimalType  Breed  Name  Sex  NeuteredStatus  Year  \\\n",
      "11731               9           0     91     1    1               1  2013   \n",
      "21329               9           1     39     1    1               0  2014   \n",
      "13372               6           0     91     1    1               1  2014   \n",
      "11293              17           0     60     1    0               0  2015   \n",
      "415                 9           0    160     1    0               1  2014   \n",
      "\n",
      "      Month Day  Color_1  \n",
      "11731    10   0       16  \n",
      "21329     1   2       19  \n",
      "13372    10   0       16  \n",
      "11293     6   4       12  \n",
      "415       8   0       19  \n",
      "best n_components by PCA CV = 8\n",
      "best n_components by FactorAnalysis CV = 5\n",
      "best n_components by PCA MLE = 9\n",
      "Best parameters: {'estimator__C': 100, 'estimator__gamma': 0.001}\n",
      "Best score: 0.56\n",
      "Preparing to scale the following dataframe:\n",
      "\n",
      "    AgeuponOutcome  AnimalType  Breed  Name  Sex  NeuteredStatus  Year Month  \\\n",
      "ID                                                                             \n",
      "1                2           0     15     1    1               0  2015    10   \n",
      "2                2           0    125     1    1               1  2014     7   \n",
      "3               18           1     39     1    0               1  2016     1   \n",
      "4                9           0     91     1    0               0  2013    12   \n",
      "5               18           0    101     1    0               1  2015     9   \n",
      "\n",
      "   Day  Color_1  \n",
      "ID               \n",
      "1    0        5  \n",
      "2    5       12  \n",
      "3    2       19  \n",
      "4    5       27  \n",
      "5    3       16  \n",
      "Wrote 11451 records to csv file.\n",
      "Complete!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "from sklearn import cross_validation, metrics, preprocessing\n",
    "from sklearn import svm\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.learning_curve import learning_curve, validation_curve #temporary\n",
    "from sklearn.decomposition import PCA, FactorAnalysis\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "TRAINING_FLAG = 0\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "def encode_ordinal(data_col):\n",
    "    \"\"\"\n",
    "    Function encodes categorical data ordinally, accepting a dataframe column\n",
    "    and returning the encoded dataframe column with a mapping list.\n",
    "    \"\"\"\n",
    "    \n",
    "    mapping = []\n",
    "    \n",
    "    categories = list(set(data_col.values))\n",
    "    random.shuffle(categories)\n",
    "    for idx, val in enumerate(categories):\n",
    "        data_col.loc[data_col == val] = str(idx)\n",
    "    data_col = data_col.astype(int)\n",
    "    mapping.append({'mapping': [(x[1], x[0]) for x in list(enumerate(categories))]},)\n",
    "    \n",
    "    return data_col, mapping\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "def breed_to_breed_group(data_col):   \n",
    "    \"\"\"\n",
    "    Function simplifies dog breeds into dog breed categories, yielding more\n",
    "    examples per category. Accepts a dataframe column of dog breeds and returns\n",
    "    a dataframe column of dog breeds mapped to categories. Function uses\n",
    "    data and structure of Andy's Kaggle script, which can be found at: \n",
    "    kaggle.com/andraszsom/shelter-animal-outcomes/dog-breeds-dog-groups/comments\n",
    "    \"\"\"\n",
    "    \n",
    "    # Import Andy's breed groups as dictionary\n",
    "    fname = './Input/dog_breed_to_category.csv'\n",
    "    breed_to_category_dict = pd.read_csv(fname, names=['Category'], index_col=0, header=None).to_dict()\n",
    "    \n",
    "    unknowns = []\n",
    "    for idx, element in enumerate(data_col):\n",
    "        # Simplify breed by removing unnecessary words\n",
    "        element = element.replace(' Shorthair','')\n",
    "        element = element.replace(' Medium Hair','')\n",
    "        element = element.replace(' Longhair','')\n",
    "        element = element.replace(' Wirehair','')\n",
    "        element = element.replace(' Rough','')\n",
    "        element = element.replace(' Smooth Coat','')\n",
    "        element = element.replace(' Smooth','')\n",
    "        element = element.replace(' Black/Tan','')\n",
    "        element = element.replace('Black/Tan ','')\n",
    "        element = element.replace(' Flat Coat','')\n",
    "        element = element.replace('Flat Coat ','')\n",
    "        element = element.replace(' Coat','')\n",
    "\n",
    "        # If more than one breed, split using '/' separator\n",
    "        if '/' in element:\n",
    "            i = 0\n",
    "            split_element = element.split('/')\n",
    "            a = ''\n",
    "            for j in split_element:\n",
    "                if j[-3:] == 'Mix':\n",
    "                    if not j[:-4] in breed_to_category_dict['Category'].keys():\n",
    "                        a += 'Unknown Mix'\n",
    "                        unknowns.append(j[:-4])\n",
    "                    else:\n",
    "                        a += breed_to_category_dict['Category'][j[:-4]]\n",
    "                else:\n",
    "                    if not j in breed_to_category_dict['Category'].keys():\n",
    "                        a += 'Unknown'\n",
    "                        unknowns.append(j)\n",
    "                    else:\n",
    "                        a += breed_to_category_dict['Category'][j]\n",
    "                a += ' / '\n",
    "            a = a[:-3]\n",
    "            data_col.iloc[idx] = a\n",
    "        else:\n",
    "            if element[-3:] == 'Mix':\n",
    "                data_col.iloc[idx] = element[:-4]\n",
    "                if not element[:-4] in breed_to_category_dict['Category'].keys():\n",
    "                    data_col.iloc[idx] = \"Unknown Mix\"\n",
    "                    unknowns.append(element[:-4])\n",
    "            else:\n",
    "                data_col.iloc[idx] = element\n",
    "                if not element in breed_to_category_dict['Category'].keys():\n",
    "                    data_col.iloc[idx] = \"Unknown\"\n",
    "                    unknowns.append(element)\n",
    "                    \n",
    "    print('Unknown dog breeds: %s\\n' % list(set(unknowns)))\n",
    "    \n",
    "    breeds = set([val for val in breed_to_category_dict['Category'].keys()])\n",
    "    # Map breed to category\n",
    "    for breed in breeds:\n",
    "        data_col.loc[data_col == breed] = breed_to_category_dict['Category'][breed]        \n",
    "    return data_col\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "def find_number(string):\n",
    "    number = re.match('^[0-9]+', string).group(0)\n",
    "    return int(number)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "def age_to_years(data_col):\n",
    "    '''\n",
    "    Takes list of strings with ages in the regex format ^[0-9]+\\b\\s+\n",
    "    and returns a list of integers with the age in years. E.g. \n",
    "    '24 months' becomes '2'.\n",
    "    '''\n",
    "    \n",
    "    data_col = data_col.reset_index(drop=True)\n",
    "    ages = set(data_col)\n",
    "    for age in ages:\n",
    "        if age[-3:] == 'day' or age[-4:] == 'days':\n",
    "            age_number = find_number(age) * 1/365\n",
    "        elif age[-4:] == 'week' or age[-5:] == 'weeks':\n",
    "            age_number = find_number(age) * 1/52\n",
    "        elif age[-5:] == 'month' or age[-6:] == 'months':\n",
    "            age_number = find_number(age) * 1/12\n",
    "        elif age[-4:] == 'year' or age[-5:] == 'years':\n",
    "            age_number = find_number(age)\n",
    "        else:\n",
    "            age_number = -1\n",
    "            print age_number\n",
    "        data_col.loc[data_col == age] = int(age_number)\n",
    "\n",
    "    return data_col\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    \"\"\"\n",
    "    Generate a simple plot of the test and traning learning curve. Taken from:\n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html.\n",
    "    Currently fails.\n",
    "    \"\"\"\n",
    "    print train_sizes\n",
    "    print type(train_sizes)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "                estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "def plot_validation_curve(estimator, X, y, param_range=np.logspace(-9, 3, 9), cv=None):\n",
    "\n",
    "    train_scores, test_scores = validation_curve(\n",
    "        estimator, X, y, param_name=\"estimator__gamma\", param_range=param_range,\n",
    "        cv=cv, scoring=\"accuracy\", n_jobs=1)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "    plt.title(\"Validation Curve with SVM\")\n",
    "    plt.xlabel(\"$\\gamma$\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    #plt.ylim(0.0, 1.1)\n",
    "    plt.semilogx(param_range, train_scores_mean, label=\"Training score\", color=\"r\")\n",
    "    plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.2, color=\"r\")\n",
    "    plt.semilogx(param_range, test_scores_mean, label=\"Cross-validation score\",\n",
    "                 color=\"g\")\n",
    "    plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.2, color=\"g\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "def retreive_map(mapping, x):\n",
    "    return([item[1] for item in mapping[0]['mapping'] if item[0] == x][0])\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "def export_to_csv(pred):\n",
    "    \"\"\"\n",
    "    Add headers and export the predictions to csv.\n",
    "    \"\"\"\n",
    "    \n",
    "    f = open('./Output/shelter_animal_outcomes_results.csv','w')\n",
    "    result_str = 'ID,Adoption,Died,Euthanasia,Return_to_owner,Transfer\\n'\n",
    "    total = 1\n",
    "    for i in range(len(pred)):\n",
    "        for j in range(len(pred[i])):\n",
    "            result_str += str(pred[i][j].astype(int)) + ','\n",
    "        result_str += '\\n'\n",
    "        total += 1\n",
    "    f.write(result_str)\n",
    "    print('Wrote %i records to csv file.' % total)\n",
    "    return\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "#----------------------------------------------------------------------\n",
    "\n",
    "# Import\n",
    "df = pd.read_csv('./input/train.csv')\n",
    "df['Regime'] = 'train'\n",
    "if TRAINING_FLAG != 1:\n",
    "    df_test = pd.read_csv('./input/test.csv')\n",
    "    df_test['Regime'] = 'test'\n",
    "    df_test['OutcomeSubtype'] = ''\n",
    "    df_test['OutcomeType'] = ''\n",
    "    df_test['AnimalID'] = ''\n",
    "    #df_test.set_index('ID')\n",
    "    df = df.append(df_test)\n",
    "    \n",
    "original_rows = df.shape[0]\n",
    "\n",
    "## Perform preprocessing\n",
    "# Separate sex and neutered status. The following functions were helpfully taken\n",
    "# from Eugenia Uchaeva's 'Take a look at the data' script:\n",
    "# https://www.kaggle.com/uchayder/shelter-animal-outcomes/take-a-look-at-the-data\n",
    "def get_sex(element):\n",
    "    \"\"\"\n",
    "    Takes string input, searches for sex within string, returns sex\n",
    "    \"\"\"\n",
    "    element = str(element)\n",
    "    if element.find('Male') >= 0: return 'male'\n",
    "    if element.find('Female') >= 0: return 'female'\n",
    "    return 'unknown'\n",
    "\n",
    "def get_neutered(element):\n",
    "    \"\"\"\n",
    "    Takes string input, searches for neutered status within string, returns \n",
    "    status\n",
    "    \"\"\"\n",
    "    element = str(element)\n",
    "    if element.find('Spayed') >= 0: return 'neutered'\n",
    "    if element.find('Neutered') >= 0: return 'neutered'\n",
    "    if element.find('Intact') >= 0: return 'intact'\n",
    "    return 'unknown'\n",
    "\n",
    "# Split SexuopnOutcome into Sex and NeuteredStatus\n",
    "df['Sex'] = df.SexuponOutcome.apply(get_sex)\n",
    "df['NeuteredStatus'] = df.SexuponOutcome.apply(get_neutered)\n",
    "\n",
    "# Convert ages into years, being careful to remove NaNs\n",
    "df = df.dropna(subset = ['AgeuponOutcome'])\n",
    "df.AgeuponOutcome = age_to_years(df.AgeuponOutcome) #could use .apply instead\n",
    "df = df.dropna(subset = ['AgeuponOutcome'])\n",
    "new_rows = df.shape[0]\n",
    "print('Dropping NaNs reduced the dataframe by %i rows.\\n' % (original_rows - new_rows))\n",
    "\n",
    "# Categorise dog breeds into breed groups\n",
    "df.Breed[df.AnimalType == 'Dog'] = breed_to_breed_group(df.Breed[df.AnimalType == 'Dog'])\n",
    "\n",
    "# Expand dates\n",
    "df.DateTime = pd.to_datetime(df.DateTime)\n",
    "df['Year'] = df.DateTime.map(lambda x: x.year).astype(str)\n",
    "df['Month'] = df.DateTime.map(lambda x: x.month).astype(str)\n",
    "df['Day'] = df.DateTime.map(lambda x: x.dayofweek).astype(str)\n",
    "\n",
    "# Encode whether animal has a name (note: loses info on whether\n",
    "# name affects adoption for sake of simplicity!)\n",
    "def has_name(name):\n",
    "    if len(str(name)) > 0: return 1\n",
    "    else: return 0\n",
    "\n",
    "#df.Name = df.Name.replace(r'\\s+', 0, regex=True)\n",
    "df.Name = df.Name.map(has_name) #Probably not working properly...\n",
    "print df.groupby('Name').count()\n",
    "\n",
    "df['Color_1'] = df.Color.str.split('/| ').str.get(0)\n",
    "    \n",
    "# Start with ordinal encoding, then try binary encoding and compare\n",
    "# performance. Ordinal encoding may be acceptable for age.\n",
    "df.AnimalType, animaltype_mapping = encode_ordinal(df.AnimalType)\n",
    "df.Sex, sex_mapping = encode_ordinal(df.Sex)\n",
    "df.NeuteredStatus, neuteredstatus_mapping = encode_ordinal(df.NeuteredStatus)\n",
    "df.AgeuponOutcome, ageuponoutcome_mapping = encode_ordinal(df.AgeuponOutcome)\n",
    "df.Breed, breed_mapping = encode_ordinal(df.Breed)\n",
    "df.Color_1, color_mapping = encode_ordinal(df.Color_1)\n",
    "\n",
    "# Line below would perform one-hot encoding\n",
    "#df = pd.concat([data_raw, pd.get_dummies(data_raw['Breed']).rename(columns = lambda x: 'Breed_' + str(x))], axis=1)\n",
    "\n",
    "#if TRAINING_FLAG != 1:\n",
    "#    df.AnimalType = df.AnimalType.map(lambda x: retreive_map(animaltype_mapping, x))\n",
    "#    df.Sex = df.Sex.map(lambda x: retreive_map(sex_mapping, x))\n",
    "#    df.NeuteredStatus = df.NeuteredStatus.map(lambda x: retreive_map(neuteredstatus_mapping, x))\n",
    "#    df.AgeuponOutcome = df.AgeuponOutcome.map(lambda x: retreive_map(ageuponoutcome_mapping, x))\n",
    "#    df.Breed = df.Breed.map(lambda x: retreive_map(breed_mapping, x))\n",
    "#    df.Color_1 = df.Color_1.map(lambda x: retreive_map(color_mapping, x))\n",
    "\n",
    "# Impute missing values\n",
    "#from sklearn.preprocessing import Imputer\n",
    "#imp = Imputer(missing_values=np.nan, strategy='mean', axis=0)\n",
    "#imp.fit(df)\n",
    "#df = imp.transform(df) #Note spits out list of lists, not df\n",
    "\n",
    "# Split df back into train and test\n",
    "df_train = df[df['Regime'] == 'train']\n",
    "df_test = df[df['Regime'] == 'test']\n",
    "\n",
    "# Keep only relevant columns (training set)\n",
    "drop_list = ['AnimalID', 'SexuponOutcome', 'DateTime', 'Color', 'Regime', 'ID']\n",
    "df_train.drop(drop_list, axis = 1, inplace = True)\n",
    "# Encode training data labels\n",
    "data_labels = df_train.OutcomeType\n",
    "lab_enc = preprocessing.LabelEncoder()\n",
    "data_labels = lab_enc.fit(data_labels).transform(data_labels)\n",
    "#data_labels = pd.get_dummies(data_labels)\n",
    "df_train.drop(['OutcomeType', 'OutcomeSubtype'], axis = 1, inplace = True)\n",
    "\n",
    "# Keep only relevant columns (test set)\n",
    "drop_list = ['AnimalID', 'OutcomeType', 'OutcomeSubtype', 'SexuponOutcome', 'DateTime', 'Color', 'Regime']\n",
    "df_test.drop(drop_list, axis = 1, inplace = True)\n",
    "\n",
    "## Train a classifier\n",
    "x_train, x_test, y_train, y_test = cross_validation.train_test_split(\n",
    "    df_train, data_labels, test_size = 0.33, random_state = 0)\n",
    "\n",
    "# Fit scaler on x_train\n",
    "print x_train.head()\n",
    "xy_scaler = preprocessing.StandardScaler()\n",
    "xy_scaler.fit(x_train)\n",
    "x_train = xy_scaler.transform(x_train)\n",
    "\n",
    "# Install PCA or FA to reduce dimensions (currently set to use PCA)\n",
    "n_features = x_train.shape[1]\n",
    "n_components = np.arange(0, n_features, 1) #options\n",
    "\n",
    "def compute_scores(X):\n",
    "    # Fit the models\n",
    "    pca = PCA()\n",
    "    fa = FactorAnalysis()\n",
    "\n",
    "    pca_scores, fa_scores = [], []\n",
    "    for n in n_components:\n",
    "        pca.n_components = n\n",
    "        fa.n_components = n\n",
    "        pca_scores.append(np.mean(cross_validation.cross_val_score(pca, X)))\n",
    "        fa_scores.append(np.mean(cross_validation.cross_val_score(fa, X)))\n",
    "    \n",
    "    return pca_scores, fa_scores\n",
    "\n",
    "for x in [(x_train)]:\n",
    "    pca_scores, fa_scores = compute_scores(x)\n",
    "    n_components_pca = n_components[np.argmax(pca_scores)]\n",
    "    n_components_fa = n_components[np.argmax(fa_scores)]\n",
    "\n",
    "    pca = PCA(n_components='mle')\n",
    "    pca.fit(x)\n",
    "    n_components_pca_mle = pca.n_components_\n",
    "\n",
    "    print(\"best n_components by PCA CV = %d\" % n_components_pca)\n",
    "    print(\"best n_components by FactorAnalysis CV = %d\" % n_components_fa)\n",
    "    print(\"best n_components by PCA MLE = %d\" % n_components_pca_mle)\n",
    "\n",
    "\n",
    "pca = PCA(n_components= n_components_pca)\n",
    "x_train = pca.fit(x_train).transform(x_train)\n",
    "\n",
    "#pca = PCA(n_components= n_components_pca_mle)\n",
    "#x_train = pca.fit(X_train).transform(X_train)\n",
    "\n",
    "#fa = FactorAnalysis(n_components= n_components_fa)\n",
    "#x_train = fa.fit(x_train).transform(x_train)\n",
    "\n",
    "# Define SVM - basic, not optimised. Use cross validation / grid search \n",
    "# to find optimal hyperparameters\n",
    "cv = cross_validation.ShuffleSplit(df_train.shape[1], n_iter=50, #should df_train be x_train?\n",
    "                                   test_size=0.1, random_state=0) \n",
    "clf_untuned = OneVsRestClassifier(svm.SVC(kernel='rbf', decision_function_shape='ovr'))\n",
    "params = {\n",
    "    'estimator__C': [1, 10, 100],\n",
    "    'estimator__gamma': [0.0001, 0.001, 0.01, 0.1, 1, 10]\n",
    "}\n",
    "clf_tuned = GridSearchCV(clf_untuned, cv=cv, param_grid=params)\n",
    "clf_tuned.fit(x_train, y_train)\n",
    "print('Best parameters: %s' % clf_tuned.best_params_)\n",
    "print('Best score: %s' % clf_tuned.best_score_)\n",
    "\n",
    "# Plot learning curve for best params\n",
    "#title = 'Learning curve (SVM)'\n",
    "#plot_learning_curve(clf_tuned.best_estimator_, title, x_train, y_train, ylim=(0.6, 1.05), cv=cv)\n",
    "#plt.show()\n",
    "\n",
    "# Plot validation curve\n",
    "#plot_validation_curve(clf_tuned.best_estimator_, x_train, y_train, cv=cv)\n",
    "#plt.show()\n",
    "\n",
    "# Fit scaler, PCA to x_test (training) or df_test (live) and predict\n",
    "def evaluate_and_predict(x):\n",
    "    x = xy_scaler.transform(x)\n",
    "    x = pca.transform(x)\n",
    "    predicted = clf_tuned.predict(x)\n",
    "    return predicted\n",
    "\n",
    "if TRAINING_FLAG == 1:\n",
    "    predicted = evaluate_and_predict(x_test)\n",
    "    print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "          % (clf_untuned, metrics.classification_report(y_test, predicted)))\n",
    "    print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(y_test, predicted))\n",
    "else:\n",
    "    df_test = df_test.set_index('ID', drop = True)\n",
    "    print('Preparing to scale the following dataframe:\\n')\n",
    "    print(df_test.head())\n",
    "    predicted = evaluate_and_predict(df_test)\n",
    "    df_test['ID'] = df_test.index\n",
    "    predicted = np.append(pd.DataFrame(df_test.ID), pd.get_dummies(predicted), 1)\n",
    "    export_to_csv(predicted)\n",
    "\n",
    "print('Complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Nearest Neighbors', 0.66422500559159026)\n",
      "('Linear SVM', 0.60495414895996424)\n",
      "('RBF SVM', 0.89213822411093713)\n",
      "('Decision Tree', 0.57968016103779918)\n",
      "('Random Forest', 0.56413554014761802)\n",
      "('AdaBoost', 0.56256989487810338)\n",
      "('Naive Bayes', 0.5712368597629166)\n",
      "('Linear Discriminant Analysis', 0.60411541042272421)\n",
      "('Quadratic Discriminant Analysis', 0.53807872959069558)\n",
      "('AdaBoosted decision trees', 0.59270856631626034)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bw8\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\sklearn\\discriminant_analysis.py:688: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "names = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \"Decision Tree\",\n",
    "         \"Random Forest\", \"AdaBoost\", \"Naive Bayes\", \"Linear Discriminant Analysis\",\n",
    "         \"Quadratic Discriminant Analysis\", \"AdaBoosted decision trees\"]\n",
    "\n",
    "knn = KNeighborsClassifier(5)\n",
    "linear_svm = svm.SVC(kernel=\"linear\", C=0.025)\n",
    "rbf_svm = svm.SVC(gamma=2, C=1)\n",
    "d_tree = DecisionTreeClassifier(max_depth=5)\n",
    "rf = RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1)\n",
    "adaboost = AdaBoostClassifier()\n",
    "naive_bayes = GaussianNB()\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "adaboost_rf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=5),\n",
    "                         algorithm=\"SAMME\",\n",
    "                         n_estimators=200)\n",
    "\n",
    "classifiers = [\n",
    "    knn,\n",
    "    linear_svm,\n",
    "    rbf_svm,\n",
    "    d_tree,\n",
    "    rf,\n",
    "    adaboost,\n",
    "    naive_bayes,\n",
    "    lda,\n",
    "    qda,\n",
    "    adaboost_rf\n",
    "]\n",
    "\n",
    "def est_score(X, y):\n",
    "\n",
    "    # iterate over classifiers\n",
    "    for name, clf in zip(names, classifiers):\n",
    "        clf.fit(X, y)\n",
    "        score = clf.score(X, y)\n",
    "        print(name, score)\n",
    "        \n",
    "est_score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 11451 records to csv file.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
